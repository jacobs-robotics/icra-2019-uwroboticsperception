---
layout: post
title: Invited Speakers
bigimg: "/img/uw_bg_1.jpg"
---

<head>
<!--link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.1/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous"-->
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
html {
  box-sizing: border-box;
}

*, *:before, *:after {
  box-sizing: inherit;
}

.card {
  box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);
  text-align: center;
  font-family: arial;
}

.title {
  color: #566573;
  font-size: 18px;
}

button {
  border: none;
  outline: 0;
  display: block;
  padding: 8px;
  color: white;
  background-color: #000;
  text-align: center;
  cursor: pointer;
  font-size: 18px;
  font-weight: bold;
  width: 100%;
}

a {
  text-decoration: none;
  font-size: 22px;
  color: black;
}

p {
  display: block;
  margin-top: 0em;
  margin-bottom: 0.5em;
  margin-left: 0;
  margin-right: 0;
}

button:hover, a:hover {
  opacity: 0.7;
}

.column-short {
  float: left;
  width: 29.0%;
  margin-bottom: 16px;
  padding: 0 0px;
}

.column-long {
  float: left;
  width: 66.0%;
  margin-bottom: 16px;
  padding: 0 0px;
}

.column-space {
  float: left;
  width: 4.0%;
  margin-bottom: 16px;
  padding: 0 0px;
}

@media screen and (max-width: 650px) {
  .column {
    width: 100%;
    display: block;
  }
}

</style>
</head>


{: .box-warning .text-center}
**Speakers shown in alphabetical order.**                                                                                                       
**Download presentation slides [HERE](http://icra-2019-uwroboticsperception.ge.issia.cnr.it/2019-05-26-presentations/).**

<br>
<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/andreas_birk.jpg" alt="Andreas Birk" style="width:100%">
      <h3>Prof. Andreas<br>Birk (TBC)</h3>
      <p class="title">Jacobs University Bremen</p>
      <!--p><button>Deep-sea perception using continuous system integration</button></p-->
      <div style="margin: 0px 0;">
        <a href="http://robotics.jacobs-university.de/people/birk"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://www.researchgate.net/profile/Andreas_Birk2/research"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=CR5fEFYAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
      </div>
     </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Underwater Perception using Continuous System Integration & Human in the Loop</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>Deep-sea robot operations and diver missions demand a high level of safety, efficiency and reliability. As a consequence, measures within the development stage have to be implemented to extensively evaluate and benchmark system components ranging from data acquisition, perception and localization to control. This session will describe an approach based on high-fidelity simulation that embeds spatial and environmental conditions from recorded real-world data. This <i>simulation in the loop</i> (SIL) methodology allows for mitigating the discrepancy between simulation and real-world conditions, e.g. regarding sensor noise. As a result, this platform allows to thoroughly investigate and benchmark behaviors of system components concurrently under real and simulated conditions. In addition, a system that integrated the diver (human) in the loop for assistance in exploratory missions and safety checking is introduced.</small></p>
    </div>
  </div>

</div>

<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/fabio.jpg" alt="Fabio Bonsignorio" style="width:100%">
      <h3>Prof. Fabio<br>Bonsignorio</h3>
      <p class="title">CEO of Heron Robots</p>
      <!--p><button>Deep-sea perception using continuous system integration</button></p-->
      <div style="margin: 0px 0;">
        <a href="http://www.heronrobots.com/about/people-info/15-fabio-bonsignorio"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://www.researchgate.net/profile/Fabio_Bonsignorio"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=lsrhSQMAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
      </div>
     </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Underwater multiagent environmental low-frequency sensing</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>The environmental chemical conditions - in term of substances with positive and negative impacts on the sustainability of local ecological networks -  of confined environments with weak streams change over time in probabilistically predictable ways. We present and discuss a reproducible and measurable approach to the deployment of a network of underwater gliders, rovs and fixed or mobile sensors deposed on the sea floor. The approach exploits Voronoi maps, multisensory fusion of different kind of chemical and non chemical sensors and a multi agent Belief Space Planning methodology.</small></p>
    </div>
  </div>

</div>

<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/yogesh_girdhar.jpg" alt="Yogesh A. Girdhar" style="width:100%">
      <h3>Dr. Yogesh A. Girdhar</h3>
      <p class="title">Woods Hole Oceanographic Institution</p>
      <div style="margin: 0px 0;">
        <a href="http://www.cim.mcgill.ca/~yogesh/"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://www.researchgate.net/profile/Yogesh_Girdhar/research"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.ca/citations?user=RLOXUngAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
      </div>
    </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Co-robotic exploration in underwater environments</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>Vision-based exploration of extreme environments with communication bottlenecks, such as underwater, is challenging due to lack of availability of high-resolution mission state information to the human operator. One approach to enable co-robotic exploration in such conditions is to summarize visual data collected by the robot using semantic scene map. Our work explores the use of an unsupervised approach to learning a generative model of the sensor data that can grow with the size and complexity of the observed input, and produce compact scene maps that can be used for communicating the current mission state. This talk will discuss the generative model along with techniques to enable online, life-long learning of these models, and extensions of the work to multi-robot environments.</small></p>
    </div>
  </div>

</div>

<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/michael_kaess.jpg" alt="Michael Kaess" style="width:100%">
      <h3>Prof. Michael Kaess</h3>
      <p class="title">Carnegie Mellon University Robot Perception Lab</p>
      <div style="margin: 0px 0;">
        <a href="https://frc.ri.cmu.edu/~kaess/"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://scholar.google.com/citations?user=27eupmsAAAAJ&hl=en"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=27eupmsAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
      </div>
    </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Localization and mapping with imaging sonar</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>Localization and mapping with imaging sonar, or forward-looking sonar, has so far been mostly limited to environments with locally planar surfaces, such as the seafloor and the central hull sections of large ships. This limitation arises from imaging sonar not providing full 3D measurements: while range and bearing angle are directly available, any surfaces along an elevation arc given by the aperture of the sonar project to the same image point. The ability to recover 3D geometry from multiple overlapping imaging sonar measurements is highly desirable. Unlike other sonar types, such as profiling or bathymetric sonar, imaging sonar covers a much larger volume of water in a single measurement, which is advantageous because of the relatively low sound speed in water. I will present our work on localizing the sonar and recovering 3D geometry of point features, which is inspired by the problem of structure-from-motion in computer vision. I will discuss our recent non-parametric formulation to address the non-Gaussian nature of distributions along the elevation arc. Finally, I will outline our ongoing exploratory work on dense surface reconstruction from imaging sonar and present some initial results.</small></p>
    </div>
  </div>

</div>


<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/ayoung_kim.jpg" alt="Ayoung Kim" style="width:100%">
      <h3>Dr. Ayoung <br>Kim</h3>
      <p class="title">Korean Advanced Institute of Science and Technology</p>
      <!--p><button>Optical image visibility enhancement for turbid water SLAM</button></p-->
      <div style="margin: 0px 0;">
        <a href="http://irap.kaist.ac.kr/~ayoung/index.html"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://scholar.google.com/citations?user=7yveufgAAAAJ&hl=en"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=7yveufgAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
      </div>
    </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Optical image visibility enhancement for turbid water SLAM</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>As human heavily relies on optical imagery information for their perception, obtaining optical images from underwater provide virtue to many underwater applications (e.g., visual SLAM, object detection, and remote operation). However, the optical images are often deteriorated depending on the water turbidity preventing the wide application, requiring image enhancement as a preprocessing. In this talk, we present three categories for the optical image visibility enhancement. Three types of enhancement approaches are based on the 1) image projection model, 2) image processing and 3) deep learning respectively. Some experimental validations will be provided such as underwater hull inspection and operation video from a severely turbid underwater. We would like to share some interesting research findings that we learned while applying each method including the advantages and disadvantages of each approach.</small></p>
    </div>
  </div>

</div>

<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/pere_ridao.png" alt="Pere Ridao" style="width:100%">
      <h3>Prof. Pere <br>Ridao</h3>
      <p class="title">University of Girona (UdG) ViCOROB</p>
      <!--p><button>Real-time Laser Scanner for Autonomous IMR applications</button></p-->
      <div style="margin: 0px 0;">
        <a href="https://sites.google.com/site/pereridaorodriguez/News"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://www.researchgate.net/profile/Pere_Ridao/research"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=RJ8xzYsAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
       </div>
    </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Real-time Laser Scanner for Autonomous IMR applications</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>While AUVs are routinely used for survey mission, Inspection Maintenance and Repair (IMR) applications are nowadays carried out by ROVs due to their intervention requirements. In spite of the recent advances, a significant improvement in the sensing capabilities of current AUVs is required to achieve autonomous intervention capabilities. While mobile and aerial manipulators can take profit of commercial of the shelf 3D cameras, those systems can not work underwater at the required ranges. In this presentation, we will present the 3LS real-time laser scaner, a recently developed and highly reconfigurable system with programable resolution/speed capabilities, able to produce up to 500.000 points per second. The system has been designed with 2 applications in mind: 1) inspection and 2) 3D perception for subsea manipulation. Experimental results corresponding to both applications using GIRONA 500 AUV will be presented and discussed.</small></p>
    </div>
  </div>

</div>

<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/jakob_schwendner.jpg" alt="Dr. Jakob Schwendner" style="width:100%">
      <h3>Dr. Jakob Schwendner</h3>
      <p class="title">Kraken Robotik GmbH</p>
      <!--p><button>(TBD)</button></p-->
      <div style="margin: 0px 0;">
        <a href="https://krakenrobotics.com/team-member/dr-jakob-schwendner/"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://www.researchgate.net/profile/Jakob_Schwendner/research"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.de/citations?user=gRvt5EIAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
       </div>
     </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Industry Speaker -- Real-time 3D inspection of underwater structures using the SeaVision system</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>Laser scanners are becoming increasingly interesting for industrial underwater applications. They offer higher resolution and accuracy compared to acoustic sensors, but also face limitations in challenging conditions. The optical properties of water are also a limitation on the transferability of technologies from the terrestrial domain. Laser stripers are the current state of the art for affordable underwater sensors, as time-of-flight systems do exist, but are still expensive and bulky. The Kraken SeaVision™ system combines a high-speed low-light color camera, with steerable red, green and blue lasers and a color LED light source. This allows for a variety of deployment options, and is especially suitable for vertical inspections of underwater structures. The content of this talk is to give an overview of the technological and operational challenges, and some examples of lab and field data.
</small></p>
    </div>
  </div>

</div>

<!-- NEW ENTRY /-->
<div class="row">
  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/katherine_skinner.jpg" alt="Katherine A. Skinner" style="width:100%">
      <h3>Katherine A. Skinner</h3>
      <p class="title">University of Michigan Robotics Institute</p>
      <!--p><button>Unsupervised Learning for Underwater Image Restoration</button></p-->
      <div style="margin: 0px 0;">
        <a href="https://kskin.github.io/katiesrobots/"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://scholar.google.com/citations?user=DsN9c-YAAAAJ&hl=en"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=DsN9c-YAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
      </div>
    </div>
  </div>
    
  <div class="column-space">
  </div>

  <div class="column-long">
    <h3>Unsupervised Learning for Underwater Image Restoration</h3>
    <div style="text-align: justify; text-justify: inter-word;">
    <p><small>In recent years, deep learning has led to impressive advances in robotic perception. State-of-the-art methods rely on gathering large datasets with hand-annotated labels for network training. However, in underwater environments, dynamic environmental conditions or operational challenges hinder efforts to collect and manually label large training sets that are representative of all possible environmental conditions a robot might encounter. This limits the performance of existing learning-based approaches for robot vision in marine environments. This talk discusses approaches for unsupervised learning to advance perceptual capabilities of underwater robots. Specifically, a learning-based approach for underwater image restoration and dense depth estimation from raw underwater imagery. Physics-based models, cross-disciplinary knowledge about the physical environment and the data collection process is leveraged to provide constraints that relax the need for ground truth labels. This leads to a hybrid model-based, data-driven framework for unsupervised learning.</small></p>
    </div>
  </div>

</div>


<!--div class="row">

  <div class="column-space">
  </div>
  <div class="column-space">
  </div>
  <div class="column-space">
  </div>
  <div class="column-space">
  </div>

  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/no_man.png" alt="Yogesh A. Girdhar" style="width:100%">
      <h3>Dr. Yogesh A. Girdhar</h3>
      <p class="title">Woods Hole Oceanographic Institution</p>
      <p><button>(TBD) Perception for co-robotic exploration in underwater envs.</button></p>
      <div style="margin: 0px 0;">
        <a href="http://www.cim.mcgill.ca/~yogesh/"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://www.researchgate.net/profile/Yogesh_Girdhar/research"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.ca/citations?user=RLOXUngAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
       </div>
     </div>
  </div>

  <div class="column-space">
  </div>

  <div class="column-short">
    <div class="card">
      <img src="/img/speakers/no_man.png" alt="Michael Kaess" style="width:100%">
      <h3>Prof. Michael Kaess</h3>
      <p class="title">Carnegie Mellon University Robot Perception Lab</p>
      <p><button>(TBD) Sensor fusion for inspection of harbor infrastructure</button></p>
      <div style="margin: 0px 0;">
        <a href="https://frc.ri.cmu.edu/~kaess/"><i class="fas fa-info-circle" style="font-size:48px;"></i></a>
        <a href="https://scholar.google.com/citations?user=27eupmsAAAAJ&hl=en"><i class="fab fa-researchgate" style="font-size:48px;"></i></a> 
        <a href="https://scholar.google.com/citations?user=27eupmsAAAAJ&hl=en"><i class="fab fa-google" style="font-size:48px;"></i></a>
       </div>
     </div>
  </div>

  <div class="column-space">
  </div>
  <div class="column-space">
  </div>
  <div class="column-space">
  </div>
  <div class="column-space">
  </div>

</div-->



